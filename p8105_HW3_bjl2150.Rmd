---
title: "p8105_HW3_bjl2150"
author: "Briana Lettsome"
date: "October 10, 2018"
output: github_document
---

```{r}
# Loading of tidyverse package
library(tidyverse)
```

# Problem 1

```{r}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")


library(p8105.datasets)


data(brfss_smart2010)
  
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health")

# Checked the unique observations within 'response' columns
unique(brfss$response)

# Ordering of the responses from "Excellent"" to "Poor"
brfss %>%
  mutate(response_levels = forcats::fct_relevel(response, c("Excellent", 
                                                            "Very Good", "Good",
                                                            "Fair", "Poor"))) 


#Wrangling dataframe to find the which states were observed at 7 locations
brfss_2002 = brfss %>%
  filter(year == 2002) %>%
  separate(locationdesc, into = c("state", "county"), sep = "-") %>%
  group_by(state) %>%
  distinct(county) %>%
  count() %>%
  filter(n == 7)
```

Coneecticut, Florida and North Carolina are the states which were observed at 
7 locations  
  
## Question 2: Making of Spaghetti Plot
```{r}
library(ggridges)

unique(brfss_smart2010$Year)

brfss_spaghetti = brfss %>%
  group_by(locationabbr, year) %>%
  distinct(locationdesc) %>%
  summarize(location_numbers = n()) %>%
  ggplot(aes(x = year, y = location_numbers, color = locationabbr)) + 
  geom_line()
```

### Question 3: Making of Table
```{r}
brfss_table = brfss %>%
  group_by(locationdesc) %>%
  filter(locationabbr == "NY", year %in% c("2002", "2006", "2010")) %>%
  spread(key = response, value = data_value) %>%
  select("Excellent", year) 

# The correct code chunk below
brfss_table_2 = brfss %>%
    filter(locationabbr == "NY", response == "Excellent") %>%
  spread(key = response, value = data_value) %>%
  filter(year %in% c("2002", "2006", "2010")) 

# Making of the table to show means and standard deveiations
brfss_table_2 %>%
  group_by(year) %>%
  summarize(mean_excellent = mean(Excellent),
            sd_excellent = sd(Excellent)) %>%
   knitr::kable(digits = 1)
```

### Question 4

```{r}

```


# Problem 2
## Instacart dataset

```{r}
# Importing instacart dataset from p8105 datasets on github
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data(instacart)

# Calling 'instacart' data into my environment and cleaning names

instacart = instacart %>% 
  janitor::clean_names()

# Used dim function to het the size of the dataset
dim(instacart)
```
This dataset is from the delivery service Instacart. It shows observations ranging
from proudct ID number and the hour of the day that a product was ordered to the 
product name and what aisle and department said product can be found in.

This dataset has 15 columns and 1,384,617 rows.





# Problem 3
