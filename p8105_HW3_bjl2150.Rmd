---
title: "p8105_HW3_bjl2150"
author: "Briana Lettsome"
date: "October 10, 2018"
output: github_document
---

```{r}
# Loading of tidyverse package
library(tidyverse)
```

# Problem 1

```{r}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")


library(p8105.datasets)


data(brfss_smart2010)
  
brfss = brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health")

# Checked the unique observations within 'response' columns
unique(brfss$response)

# Ordering of the responses from "Excellent"" to "Poor"
brfss %>%
  mutate(response_levels = forcats::fct_relevel(response, c("Excellent", 
                                                            "Very Good", "Good",
                                                            "Fair", "Poor"))) 


#Wrangling dataframe to find the which states were observed at 7 locations
brfss_2002 = brfss %>%
  filter(year == 2002) %>%
  separate(locationdesc, into = c("state", "county"), sep = "-") %>%
  group_by(state) %>%
  distinct(county) %>%
  count() %>%
  filter(n == 7)
```

Coneecticut, Florida and North Carolina are the states which were observed at 
7 locations  
  
## Question 2: Making of Spaghetti Plot
```{r}
library(ggridges)

unique(brfss_smart2010$Year)

brfss_spaghetti = brfss %>%
  group_by(locationabbr, year) %>%
  distinct(locationdesc) %>%
  summarize(location_numbers = n()) %>%
  ggplot(aes(x = year, y = location_numbers, color = locationabbr)) + 
  geom_line()
```

### Question 3: Making of Table
```{r}
brfss_table = brfss %>%
  group_by(locationdesc) %>%
  filter(locationabbr == "NY", year %in% c("2002", "2006", "2010")) %>%
  spread(key = response, value = data_value) %>%
  select("Excellent", year) 

# The correct code chunk below
brfss_table_2 = brfss %>%
    filter(locationabbr == "NY", response == "Excellent") %>%
  spread(key = response, value = data_value) %>%
  filter(year %in% c("2002", "2006", "2010")) 

# Making of the table to show means and standard deveiations
brfss_table_2 %>%
  group_by(year) %>%
  summarize(mean_excellent = mean(Excellent),
            sd_excellent = sd(Excellent)) %>%
   knitr::kable(digits = 1)
```

### Question 4

```{r}

```


# Problem 2
## Instacart dataset

```{r}
# Importing instacart dataset from p8105 datasets on github
devtools::install_github("p8105/p8105.datasets")

library(p8105.datasets)

data(instacart)

# Calling 'instacart' data into my environment and cleaning names

instacart = instacart %>% 
  janitor::clean_names()

# Used dim function to het the size of the dataset
dim(instacart)
```
This dataset is from the delivery service Instacart. It shows observations ranging
from proudct ID number and the hour of the day that a product was ordered to the 
product name and what aisle and department said product can be found in.

This dataset has 15 columns and 1,384,617 rows.

```{r}
library(tidyverse)

# Answering how many aisles there are
instacart_1A = instacart %>%
  select(aisle) %>%
  distinct() %>%
  count()

# Answering which aisles are the most items ordered from
instacart_1B = instacart %>%
  select(product_name, aisle) %>% 
  count(aisle) %>% 
  arrange(desc(n))

# Problem 2 - Making of plot

# Problem 3 - Making table of most popular items



  
# 2.4

  instacart_4 = instacart %>%
    select(order_hour_of_day, product_name, order_dow) %>%
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
    group_by(order_dow, product_name) %>%
    summarize(mean_hour = mean(order_hour_of_day, na.rm = TRUE)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 1)



  
  




```
`r instacart_4`
There are 134 aisles in the instacart dataset.

The aisle with withthe most items ordered are fresh vegetables, fresh fruits, and
packages vegetables fruits.



# Problem 3
